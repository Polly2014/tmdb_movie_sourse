# ç»ƒä¹ é¢˜ç­”æ¡ˆå‚è€ƒ

## ç»ƒä¹ ä¸€ï¼šFastAPIåŸºç¡€

### 1. ä¸ªäººä¿¡æ¯API

```python
@app.get("/about")
async def about():
    """è¿”å›ä¸ªäººä¿¡æ¯"""
    return {
        "name": "å¼ ä¸‰",
        "major": "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯",
        "grade": "å¤§ä¸‰",
        "hobbies": ["ç¼–ç¨‹", "çœ‹ç”µå½±", "æ‰“ç¯®çƒ"],
        "skills": ["Python", "Java", "Webå¼€å‘"]
    }
```

### 2. è®¡ç®—å™¨API

```python
from fastapi import Query

@app.get("/calculate")
async def calculate(
    a: float = Query(..., description="ç¬¬ä¸€ä¸ªæ•°å­—"),
    b: float = Query(..., description="ç¬¬äºŒä¸ªæ•°å­—"),
    op: str = Query(..., regex="^(add|subtract|multiply|divide)$", description="æ“ä½œç¬¦")
):
    """è®¡ç®—å™¨API"""
    result = 0
    
    if op == "add":
        result = a + b
        operation = f"{a} + {b}"
    elif op == "subtract":
        result = a - b
        operation = f"{a} - {b}"
    elif op == "multiply":
        result = a * b
        operation = f"{a} Ã— {b}"
    elif op == "divide":
        if b == 0:
            raise HTTPException(status_code=400, detail="é™¤æ•°ä¸èƒ½ä¸º0")
        result = a / b
        operation = f"{a} Ã· {b}"
    
    return {
        "operation": operation,
        "result": result
    }
```

### 3. å­¦ç”ŸæŸ¥è¯¢API

```python
from pydantic import BaseModel

class Student(BaseModel):
    """å­¦ç”Ÿæ•°æ®æ¨¡å‹"""
    id: int
    name: str
    age: int
    major: str
    gpa: float = 0.0

# æ¨¡æ‹Ÿå­¦ç”Ÿæ•°æ®åº“
students_db = {
    1: Student(id=1, name="å¼ ä¸‰", age=20, major="è®¡ç®—æœºç§‘å­¦", gpa=3.8),
    2: Student(id=2, name="æå››", age=21, major="è½¯ä»¶å·¥ç¨‹", gpa=3.6),
    3: Student(id=3, name="ç‹äº”", age=19, major="æ•°æ®ç§‘å­¦", gpa=3.9)
}

@app.get("/students/{student_id}", response_model=Student)
async def get_student(student_id: int):
    """è·å–å­¦ç”Ÿä¿¡æ¯"""
    if student_id not in students_db:
        raise HTTPException(status_code=404, detail=f"å­¦ç”ŸID {student_id} ä¸å­˜åœ¨")
    
    return students_db[student_id]

@app.get("/students", response_model=List[Student])
async def get_all_students():
    """è·å–æ‰€æœ‰å­¦ç”Ÿ"""
    return list(students_db.values())
```

---

## ç»ƒä¹ äºŒï¼šæ•°æ®æ¨¡å‹å’ŒCRUD

### 1. é«˜çº§æœç´¢

```python
@app.get("/movies/advanced-search", response_model=List[Movie])
async def advanced_search(
    year_from: Optional[int] = Query(None, ge=1900, description="èµ·å§‹å¹´ä»½"),
    year_to: Optional[int] = Query(None, le=2030, description="ç»“æŸå¹´ä»½"),
    min_rating: Optional[float] = Query(None, ge=0, le=10, description="æœ€ä½è¯„åˆ†"),
    max_rating: Optional[float] = Query(None, ge=0, le=10, description="æœ€é«˜è¯„åˆ†"),
    genre: Optional[str] = Query(None, description="ç”µå½±ç±»å‹")
):
    """
    é«˜çº§æœç´¢åŠŸèƒ½
    æ”¯æŒå¤šä¸ªæ¡ä»¶ç»„åˆç­›é€‰
    """
    results = movies_db.copy()
    
    # æŒ‰å¹´ä»½ç­›é€‰
    if year_from:
        results = [m for m in results if m.year >= year_from]
    if year_to:
        results = [m for m in results if m.year <= year_to]
    
    # æŒ‰è¯„åˆ†ç­›é€‰
    if min_rating:
        results = [m for m in results if m.rating >= min_rating]
    if max_rating:
        results = [m for m in results if m.rating <= max_rating]
    
    # æŒ‰ç±»å‹ç­›é€‰
    if genre:
        results = [m for m in results if genre in m.genres]
    
    # æŒ‰è¯„åˆ†é™åºæ’åˆ—
    results.sort(key=lambda x: x.rating, reverse=True)
    
    return results
```

### 2. å¯¼æ¼”ç»Ÿè®¡

```python
@app.get("/directors", tags=["ç»Ÿè®¡"])
async def get_directors_stats():
    """
    è·å–å¯¼æ¼”ç»Ÿè®¡ä¿¡æ¯
    è¿”å›æ‰€æœ‰å¯¼æ¼”åŠå…¶ä½œå“æ•°é‡
    """
    directors_count = {}
    directors_movies = {}
    
    # ç»Ÿè®¡æ¯ä¸ªå¯¼æ¼”çš„ç”µå½±
    for movie in movies_db:
        if directors_count.get(movie.director):
            directors_count[movie.director] += 1
            directors_movies[movie.director].append(movie.title)
        else:
            directors_count[movie.director] = 1
            directors_movies[movie.director] = [movie.title]
    
    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
    directors_list = [
        {
            "director": director,
            "movie_count": count,
            "movies": directors_movies[director]
        }
        for director, count in directors_count.items()
    ]
    
    # æŒ‰ä½œå“æ•°é‡é™åºæ’åˆ—
    directors_list.sort(key=lambda x: x["movie_count"], reverse=True)
    
    return {
        "total_directors": len(directors_list),
        "directors": directors_list
    }
```

### 3. æ‰¹é‡æ“ä½œ

```python
class BatchMovieCreate(BaseModel):
    """æ‰¹é‡åˆ›å»ºç”µå½±çš„æ•°æ®æ¨¡å‹"""
    movies: List[MovieCreate]

@app.post("/movies/batch", response_model=List[Movie], tags=["ç”µå½±"])
async def batch_create_movies(batch: BatchMovieCreate):
    """
    æ‰¹é‡åˆ›å»ºç”µå½±
    """
    global next_id
    
    created_movies = []
    
    for movie_data in batch.movies:
        # åˆ›å»ºæ–°ç”µå½±
        new_movie = Movie(
            id=next_id,
            **movie_data.dict()
        )
        
        # æ·»åŠ åˆ°æ•°æ®åº“
        movies_db.append(new_movie)
        created_movies.append(new_movie)
        next_id += 1
    
    return created_movies

# ä½¿ç”¨ç¤ºä¾‹ï¼š
"""
POST /movies/batch
{
  "movies": [
    {
      "title": "ç”µå½±1",
      "director": "å¯¼æ¼”1",
      "year": 2020,
      "rating": 8.0,
      "genres": ["å‰§æƒ…"]
    },
    {
      "title": "ç”µå½±2",
      "director": "å¯¼æ¼”2",
      "year": 2021,
      "rating": 8.5,
      "genres": ["å–œå‰§"]
    }
  ]
}
"""
```

---

## ç»ƒä¹ ä¸‰ï¼šè±†ç“£APIé›†æˆ

### 1. æŒ‰å¯¼æ¼”æœç´¢

```python
@app.get("/search/director", tags=["æœç´¢"])
async def search_by_director(
    director: str = Query(..., min_length=1, description="å¯¼æ¼”å§“å"),
    count: int = Query(20, ge=1, le=50, description="è¿”å›æ•°é‡")
):
    """
    æŒ‰å¯¼æ¼”æœç´¢ç”µå½±
    è¿”å›è¯¥å¯¼æ¼”çš„æ‰€æœ‰ç”µå½±ï¼ŒæŒ‰è¯„åˆ†é™åºæ’åˆ—
    """
    # ä½¿ç”¨è±†ç“£æœç´¢API
    params = {
        "q": director,
        "count": 100  # å¤šè·å–ä¸€äº›ï¼Œä¾¿äºç­›é€‰
    }
    
    data = await fetch_from_douban("v2/movie/search", params)
    
    # è§£æå¹¶ç­›é€‰
    all_movies = [parse_movie_data(item) for item in data.get('subjects', [])]
    
    # ç­›é€‰å‡ºè¯¥å¯¼æ¼”çš„ç”µå½±
    director_movies = [
        movie for movie in all_movies 
        if director in ' '.join(movie.directors)
    ]
    
    # æŒ‰è¯„åˆ†é™åºæ’åˆ—
    director_movies.sort(key=lambda x: x.rating, reverse=True)
    
    return {
        "director": director,
        "count": len(director_movies),
        "movies": director_movies[:count]
    }
```

### 2. ç”µå½±å¯¹æ¯”

```python
@app.get("/compare", tags=["å¯¹æ¯”"])
async def compare_movies(
    movie1_id: str = Query(..., description="ç¬¬ä¸€éƒ¨ç”µå½±ID"),
    movie2_id: str = Query(..., description="ç¬¬äºŒéƒ¨ç”µå½±ID")
):
    """
    å¯¹æ¯”ä¸¤éƒ¨ç”µå½±
    """
    # è·å–ä¸¤éƒ¨ç”µå½±çš„è¯¦ç»†ä¿¡æ¯
    data1 = await fetch_from_douban(f"v2/movie/subject/{movie1_id}")
    data2 = await fetch_from_douban(f"v2/movie/subject/{movie2_id}")
    
    movie1 = parse_movie_data(data1)
    movie2 = parse_movie_data(data2)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    common_genres = set(movie1.genres) & set(movie2.genres)
    
    # æ„å»ºå¯¹æ¯”ç»“æœ
    comparison = {
        "movie1": {
            "title": movie1.title,
            "rating": movie1.rating,
            "year": movie1.year,
            "genres": movie1.genres,
            "directors": movie1.directors
        },
        "movie2": {
            "title": movie2.title,
            "rating": movie2.rating,
            "year": movie2.year,
            "genres": movie2.genres,
            "directors": movie2.directors
        },
        "comparison": {
            "rating_diff": abs(movie1.rating - movie2.rating),
            "year_diff": abs(int(movie1.year) - int(movie2.year)) if movie1.year and movie2.year else None,
            "common_genres": list(common_genres),
            "genre_similarity": len(common_genres) / max(len(movie1.genres), len(movie2.genres)) if movie1.genres or movie2.genres else 0,
            "better_rating": movie1.title if movie1.rating > movie2.rating else movie2.title,
            "conclusion": f"{movie1.title} å’Œ {movie2.title} çš„è¯„åˆ†ç›¸å·® {abs(movie1.rating - movie2.rating):.1f} åˆ†"
        }
    }
    
    return comparison
```

### 3. ä¸ªæ€§åŒ–æ¨è

```python
@app.get("/recommend/similar", tags=["æ¨è"])
async def recommend_similar(
    movie_id: str = Query(..., description="ç”µå½±ID"),
    count: int = Query(10, ge=1, le=20, description="æ¨èæ•°é‡")
):
    """
    åŸºäºç”µå½±æ¨èç›¸ä¼¼ç”µå½±
    æ ¹æ®ç±»å‹å’Œè¯„åˆ†è¿›è¡ŒåŒ¹é…
    """
    # è·å–åŸºå‡†ç”µå½±ä¿¡æ¯
    base_data = await fetch_from_douban(f"v2/movie/subject/{movie_id}")
    base_movie = parse_movie_data(base_data)
    
    # è·å–Top250ä½œä¸ºæ¨èæ± 
    top_data = await fetch_from_douban("v2/movie/top250", {"count": 100})
    all_movies = [parse_movie_data(item) for item in top_data.get('subjects', [])]
    
    # æ’é™¤åŸºå‡†ç”µå½±è‡ªå·±
    all_movies = [m for m in all_movies if m.id != movie_id]
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    recommendations = []
    for movie in all_movies:
        # è®¡ç®—ç±»å‹ç›¸ä¼¼åº¦
        common_genres = set(base_movie.genres) & set(movie.genres)
        genre_similarity = len(common_genres) / max(len(base_movie.genres), len(movie.genres), 1)
        
        # è®¡ç®—è¯„åˆ†ç›¸ä¼¼åº¦ï¼ˆå·®è·è¶Šå°è¶Šç›¸ä¼¼ï¼‰
        rating_similarity = 1 - abs(base_movie.rating - movie.rating) / 10
        
        # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆç±»å‹æƒé‡0.6ï¼Œè¯„åˆ†æƒé‡0.4ï¼‰
        total_similarity = genre_similarity * 0.6 + rating_similarity * 0.4
        
        recommendations.append({
            "movie": movie,
            "similarity": total_similarity,
            "common_genres": list(common_genres)
        })
    
    # æŒ‰ç›¸ä¼¼åº¦æ’åº
    recommendations.sort(key=lambda x: x["similarity"], reverse=True)
    
    return {
        "base_movie": {
            "title": base_movie.title,
            "genres": base_movie.genres,
            "rating": base_movie.rating
        },
        "recommendations": [
            {
                "movie": r["movie"].dict(),
                "similarity_score": round(r["similarity"], 2),
                "match_reason": f"å…±åŒç±»å‹: {', '.join(r['common_genres'])}" if r['common_genres'] else "è¯„åˆ†æ¥è¿‘"
            }
            for r in recommendations[:count]
        ]
    }
```

---

## æŒ‘æˆ˜é¢˜ç­”æ¡ˆ

### 1. ç¼“å­˜æœºåˆ¶

```python
from datetime import datetime, timedelta
from typing import Dict, Tuple, Any

# ç¼“å­˜å­˜å‚¨
cache: Dict[str, Tuple[Any, datetime]] = {}

def get_cache(key: str, ttl_minutes: int = 5) -> Any:
    """
    ä»ç¼“å­˜è·å–æ•°æ®
    Args:
        key: ç¼“å­˜é”®
        ttl_minutes: è¿‡æœŸæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    """
    if key in cache:
        data, timestamp = cache[key]
        if datetime.now() - timestamp < timedelta(minutes=ttl_minutes):
            return data
    return None

def set_cache(key: str, data: Any):
    """è®¾ç½®ç¼“å­˜"""
    cache[key] = (data, datetime.now())

# åœ¨æœç´¢APIä¸­ä½¿ç”¨
@app.get("/search")
async def search_movies_with_cache(q: str, count: int = 20):
    """å¸¦ç¼“å­˜çš„æœç´¢"""
    cache_key = f"search:{q}:{count}"
    
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_result = get_cache(cache_key)
    if cached_result:
        return {**cached_result, "from_cache": True}
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨API
    params = {"q": q, "count": count}
    data = await fetch_from_douban("v2/movie/search", params)
    
    movies = [parse_movie_data(item) for item in data.get('subjects', [])]
    
    result = {
        "count": len(movies),
        "movies": [m.dict() for m in movies],
        "from_cache": False
    }
    
    # å­˜å…¥ç¼“å­˜
    set_cache(cache_key, result)
    
    return result
```

### 2. é”™è¯¯é‡è¯•

```python
import asyncio
from typing import Callable

async def retry_with_backoff(
    func: Callable,
    max_retries: int = 3,
    initial_delay: float = 1.0
):
    """
    å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶
    """
    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            if attempt == max_retries - 1:
                # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise
            
            # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
            delay = initial_delay * (2 ** attempt)
            print(f"è¯·æ±‚å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
            await asyncio.sleep(delay)

# ä½¿ç”¨ç¤ºä¾‹
async def fetch_from_douban_with_retry(endpoint: str, params: dict = None):
    """å¸¦é‡è¯•çš„è±†ç“£APIè¯·æ±‚"""
    
    async def make_request():
        url = f"{DOUBAN_API_BASE}/{endpoint}"
        async with httpx.AsyncClient(timeout=TIMEOUT) as client:
            response = await client.get(url, params=params)
            response.raise_for_status()
            return response.json()
    
    return await retry_with_backoff(make_request, max_retries=3)
```

### 3. APIé™æµ

```python
from collections import defaultdict
from datetime import datetime, timedelta
from fastapi import Request

# å­˜å‚¨æ¯ä¸ªIPçš„è¯·æ±‚è®°å½•
request_records: Dict[str, list] = defaultdict(list)

def check_rate_limit(ip: str, max_requests: int = 10, window_minutes: int = 1) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™æµ
    Args:
        ip: å®¢æˆ·ç«¯IP
        max_requests: æœ€å¤§è¯·æ±‚æ•°
        window_minutes: æ—¶é—´çª—å£ï¼ˆåˆ†é’Ÿï¼‰
    Returns:
        True: æœªè¶…é™ï¼ŒFalse: è¶…é™
    """
    now = datetime.now()
    cutoff = now - timedelta(minutes=window_minutes)
    
    # è·å–è¯¥IPçš„è¯·æ±‚è®°å½•
    records = request_records[ip]
    
    # ç§»é™¤è¿‡æœŸè®°å½•
    records[:] = [t for t in records if t > cutoff]
    
    # æ£€æŸ¥æ˜¯å¦è¶…é™
    if len(records) >= max_requests:
        return False
    
    # è®°å½•æœ¬æ¬¡è¯·æ±‚
    records.append(now)
    return True

# åˆ›å»ºé™æµä¾èµ–
from fastapi import HTTPException

async def rate_limit_dependency(request: Request):
    """é™æµä¸­é—´ä»¶"""
    client_ip = request.client.host
    
    if not check_rate_limit(client_ip):
        raise HTTPException(
            status_code=429,
            detail="è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
        )

# åœ¨APIä¸­ä½¿ç”¨
from fastapi import Depends

@app.get("/search", dependencies=[Depends(rate_limit_dependency)])
async def search_with_rate_limit(q: str):
    """å¸¦é™æµçš„æœç´¢API"""
    # ... åŸæœ‰é€»è¾‘
    pass
```

---

## å®Œæ•´ç¤ºä¾‹ï¼šç»¼åˆæ‰€æœ‰æ”¹è¿›

```python
"""
ç»¼åˆç¤ºä¾‹ï¼šç¼“å­˜ + é‡è¯• + é™æµ
"""

from fastapi import FastAPI, Depends, HTTPException, Request, Query
import httpx
import asyncio
from datetime import datetime, timedelta
from collections import defaultdict
from typing import Dict, Any, Tuple, Callable

app = FastAPI(title="æ”¹è¿›ç‰ˆè±†ç“£ç”µå½±API")

# ========== ç¼“å­˜ç³»ç»Ÿ ==========
cache: Dict[str, Tuple[Any, datetime]] = {}

def get_cache(key: str, ttl_minutes: int = 5):
    if key in cache:
        data, timestamp = cache[key]
        if datetime.now() - timestamp < timedelta(minutes=ttl_minutes):
            return data
    return None

def set_cache(key: str, data: Any):
    cache[key] = (data, datetime.now())

# ========== é‡è¯•æœºåˆ¶ ==========
async def retry_with_backoff(func: Callable, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            delay = 2 ** attempt
            await asyncio.sleep(delay)

# ========== é™æµç³»ç»Ÿ ==========
request_records: Dict[str, list] = defaultdict(list)

async def rate_limit(request: Request, max_requests: int = 10):
    ip = request.client.host
    now = datetime.now()
    cutoff = now - timedelta(minutes=1)
    
    records = request_records[ip]
    records[:] = [t for t in records if t > cutoff]
    
    if len(records) >= max_requests:
        raise HTTPException(status_code=429, detail="è¯·æ±‚è¿‡äºé¢‘ç¹")
    
    records.append(now)

# ========== APIç«¯ç‚¹ ==========
@app.get("/search", dependencies=[Depends(rate_limit)])
async def search_with_all_improvements(q: str, count: int = 20):
    """
    ç»¼åˆæ”¹è¿›çš„æœç´¢API
    - ç¼“å­˜
    - é‡è¯•
    - é™æµ
    """
    cache_key = f"search:{q}:{count}"
    
    # å°è¯•ç¼“å­˜
    cached = get_cache(cache_key)
    if cached:
        return {**cached, "from_cache": True}
    
    # å¸¦é‡è¯•çš„APIè°ƒç”¨
    async def fetch():
        async with httpx.AsyncClient(timeout=10) as client:
            response = await client.get(
                f"{DOUBAN_API_BASE}/v2/movie/search",
                params={"q": q, "count": count}
            )
            response.raise_for_status()
            return response.json()
    
    data = await retry_with_backoff(fetch)
    
    result = {
        "count": len(data.get('subjects', [])),
        "movies": data.get('subjects', []),
        "from_cache": False
    }
    
    # å­˜å…¥ç¼“å­˜
    set_cache(cache_key, result)
    
    return result
```

---

**è¿™äº›ç­”æ¡ˆä»…ä¾›å‚è€ƒï¼Œé¼“åŠ±å­¦ç”Ÿè‡ªå·±æ€è€ƒå’Œå®ç°ï¼** ğŸ’ª
